import os
import re
import glob
import numpy as np
import os.path as osp
from scipy.io import loadmat
import torch
from collections import Counter
# from tools.utils import mkdir_if_missing, write_json, read_json


class DukeMTMCreID(object):
    """
    DukeMTMC-reID

    Reference:
    1. Ristani et al. Performance Measures and a Data Set for Multi-Target, Multi-Camera Tracking. ECCVW 2016.
    2. Zheng et al. Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in vitro. ICCV 2017.

    URL: https://github.com/layumi/DukeMTMC-reID_evaluation
    
    Dataset statistics:
    # identities: 1404 (train + query)
    # images:16522 (train) + 2228 (query) + 17661 (gallery)
    # cameras: 8
    """
    root_folder = 'DukeMTMC-reID'

    def __init__(self, root='data', format_tag='tensor', pretrained='CLIP', test_metrix_only=False, **kwargs):
        self.tag = format_tag
        self.test_metrix_only = test_metrix_only
        if self.tag == 'tensor':
            self.dataset_dir = osp.join(root, self.root_folder, 'tensor', pretrained)
        else:
            self.dataset_dir = osp.join(root, self.root_folder, 'pytorch')
        self.train_dir = osp.join(self.dataset_dir, 'train_all')
        self.query_dir = osp.join(self.dataset_dir, 'query')
        self.gallery_dir = osp.join(self.dataset_dir, 'gallery')
        self.cluster_dir = osp.join(root, self.root_folder, 'kmeans_results', pretrained)

        self._check_before_run()

        train, num_train_pids, num_train_imgs, train_centroids = self._process_dir(self.train_dir, self.tag, self.test_metrix_only, relabel=True)
        query, num_query_pids, num_query_imgs, query_centroids = self._process_dir(self.query_dir, self.tag, self.test_metrix_only, relabel=False)
        gallery, num_gallery_pids, num_gallery_imgs, gallery_centroids = self._process_dir(self.gallery_dir, self.tag, self.test_metrix_only, relabel=False)

        num_total_pids = num_train_pids + num_query_pids
        num_total_imgs = num_train_imgs + num_query_imgs + num_gallery_imgs

        if self.tag == 'tensor':
            print("=> DukeMTMC-reID tensor loaded")
        else:
            print("=> DukeMTMC-reID loaded")

        print("Dataset statistics:")
        print("  ------------------------------")
        print("  subset   | # ids | # images")
        print("  ------------------------------")
        print("  train    | {:5d} | {:8d}".format(num_train_pids, num_train_imgs))
        print("  query    | {:5d} | {:8d}".format(num_query_pids, num_query_imgs))
        print("  gallery  | {:5d} | {:8d}".format(num_gallery_pids, num_gallery_imgs))
        print("  ------------------------------")
        print("  total    | {:5d} | {:8d}".format(num_total_pids, num_total_imgs))
        print("  ------------------------------")

        self.train = train
        self.query = query
        self.gallery = gallery

        self.num_train_pids = num_train_pids
        self.num_query_pids = num_query_pids
        self.num_gallery_pids = num_gallery_pids

        self.train_centroids = train_centroids
        self.query_centroids = query_centroids
        self.gallery_centroids = gallery_centroids

    def _check_before_run(self):
        """Check if all files are available before going deeper"""
        if not osp.exists(self.dataset_dir):
            raise RuntimeError("'{}' is not available".format(self.dataset_dir))
        if not osp.exists(self.train_dir):
            raise RuntimeError("'{}' is not available".format(self.train_dir))
        if not osp.exists(self.query_dir):
            raise RuntimeError("'{}' is not available".format(self.query_dir))
        if not osp.exists(self.gallery_dir):
            raise RuntimeError("'{}' is not available".format(self.gallery_dir))

    def _process_dir(self, dir_path, tag, test_metrix_only, relabel=False):
        if tag == 'tensor':
            img_paths = glob.glob(osp.join(dir_path, '*/*.pt'))
        else:
            img_paths = glob.glob(osp.join(dir_path, '*/*.jpg'))

        if not test_metrix_only:
            _, path2label, centroids = self._process_cluster(dir_path)
        else:
            centroids = None


        pattern = re.compile(r'([-\d]+)_c(\d)')

        pid_container = set()
        for img_path in img_paths:
            pid, _ = map(int, pattern.search(img_path).groups())
            pid_container.add(pid)
        pid2label = {pid:label for label, pid in enumerate(pid_container)}

        dataset = []
        for img_path in img_paths:
            pid, camid = map(int, pattern.search(img_path).groups())
            file_name = osp.basename(img_path)
            file_name = re.sub(r'\.pt$', '', file_name)
            if not test_metrix_only:
                clurster_id = path2label[file_name]
            else:
                clurster_id = 0
            assert 1 <= camid <= 8
            camid -= 1 # index starts from 0
            if relabel: pid = pid2label[pid]
            dataset.append((img_path, pid, camid, clurster_id))

        num_pids = len(pid_container)
        num_imgs = len(dataset)
        return dataset, num_pids, num_imgs, centroids

    def _process_cluster(self, dir_path, n_clusters=25, sim_mode='euclidean'):
        if 'train' in dir_path:
            folder_type = 'train_all'
        elif 'query' in dir_path:
            folder_type = 'query'
        elif 'gallery' in dir_path:
            folder_type = 'gallery'
        else:
            raise RuntimeError("Unkown folder type")
        kmeans_file = osp.join(self.cluster_dir, '{}_{}k_{}.pt'.format(folder_type, n_clusters, sim_mode))
        print("Loading cluster results from '{}'".format(kmeans_file))
        # load .pt files
        cluster_resutls = torch.load(kmeans_file)
        labels = cluster_resutls['labels']
        path2label = cluster_resutls['path2label']
        centroids = cluster_resutls['centroids']

        counter = Counter(labels.cpu().numpy())
        sorted_counter = sorted(counter.items(), key=lambda x: x[0])  # sort by element
        print("Clustering stastistics:", sorted_counter)
        return labels, path2label, centroids

# unit test
if __name__ == '__main__':
    root = "/home/zhengwei/github/datasets/"
    dataset = DukeMTMCreID(root=root, format_tag='tensor')