{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Prepare dataset for training\n",
    "# You only need to change this line to your dataset download path\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "download_path = 'D:\\Datasets\\DukeMTMC-reID'\n",
    "\n",
    "if 'cuhk' in download_path:\n",
    "    suffix = 'png'\n",
    "else:\n",
    "    suffix = 'jpg'\n",
    "\n",
    "if not os.path.isdir(download_path):\n",
    "    print('please change the download_path')\n",
    "\n",
    "save_path = download_path + '/pytorch'\n",
    "if not os.path.isdir(save_path):\n",
    "    os.mkdir(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_path = download_path + '/query'\n",
    "query_save_path = download_path + '/pytorch/query'\n",
    "if not os.path.isdir(query_save_path):\n",
    "    os.mkdir(query_save_path)\n",
    "    \n",
    "for root, dirs, files in os.walk(query_path, topdown=True):\n",
    "    for name in files:\n",
    "        if not name[-3:] == suffix:\n",
    "            continue\n",
    "        ID = name.split('_')\n",
    "        src_path = query_path + '/' + name\n",
    "        dst_path = query_save_path + '/' + ID[0]\n",
    "        if not os.path.isdir(dst_path):\n",
    "            os.mkdir(dst_path)\n",
    "        copyfile(src_path, dst_path + '/' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gallery\n",
    "gallery_path = download_path + '/bounding_box_test'\n",
    "gallery_save_path = download_path + '/pytorch/gallery'\n",
    "if not os.path.isdir(gallery_save_path):\n",
    "    os.mkdir(gallery_save_path)\n",
    "\n",
    "for root, dirs, files in os.walk(gallery_path, topdown=True):\n",
    "    for name in files:\n",
    "        if not name[-3:] == suffix:\n",
    "            continue\n",
    "        ID = name.split('_')\n",
    "        src_path = gallery_path + '/' + name\n",
    "        dst_path = gallery_save_path + '/' + ID[0]\n",
    "        if not os.path.isdir(dst_path):\n",
    "            os.mkdir(dst_path)\n",
    "        copyfile(src_path, dst_path + '/' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# train_all\n",
    "train_path = download_path + '/bounding_box_train'\n",
    "train_save_path = download_path + '/pytorch/train_all'\n",
    "if not os.path.isdir(train_save_path):\n",
    "    os.mkdir(train_save_path)\n",
    "\n",
    "for root, dirs, files in os.walk(train_path, topdown=True):\n",
    "    for name in files:\n",
    "        if not name[-3:] == suffix:\n",
    "            continue\n",
    "        ID = name.split('_')\n",
    "        src_path = train_path + '/' + name\n",
    "        dst_path = train_save_path + '/' + ID[0]\n",
    "        if not os.path.isdir(dst_path):\n",
    "            os.mkdir(dst_path)\n",
    "        copyfile(src_path, dst_path + '/' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Datasets\\DukeMTMC-reID/bounding_box_train\n"
     ]
    }
   ],
   "source": [
    "train_path = download_path + '/bounding_box_train'\n",
    "cnt = 0\n",
    "root, dirs, files = next(os.walk(train_path, topdown=True))\n",
    "\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Official code of Open-Clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
    "tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
    "\n",
    "image = preprocess(Image.open(\"CLIP.png\")).unsqueeze(0)\n",
    "\n",
    "text = tokenizer([\"a diagram\", \"a dog\", \"a cat\"])\n",
    "\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "print(\"Label probs:\", text_probs)  # prints: [[1., 0., 0.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_path: D:/Datasets/DukeMTMC-reID/pytorch/train_all\n",
      "root: D:\\Datasets\\DukeMTMC-reID/bounding_box_train\n",
      "0001_c2_f0046182 .jpg\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-c430558d7091>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0msingle_image_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0msingle_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msingle_image_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0msingle_image_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msingle_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "\n",
    "train_path = 'D:/Datasets/DukeMTMC-reID/pytorch/train_all'\n",
    "print('train_path:', train_path)\n",
    "\n",
    "feature_path = 'D:/Datasets/DukeMTMC-reID/tensors/train_all'\n",
    "\n",
    "# get all folders in the train_path\n",
    "dirs = os.listdir(train_path)\n",
    "for dir in dirs:\n",
    "    feature_root= os.path.join(feature_path, dir)\n",
    "    os.makedirs(feature_root, exist_ok=True)\n",
    "        \n",
    "    root, _, files = next(os.walk(train_path + '/' + dir))\n",
    "    print('root:', root)\n",
    "    for name in files:\n",
    "        pre, ext = os.path.splitext(name)\n",
    "        if ext != suffix:\n",
    "            continue\n",
    "        single_image_path = os.path.join(root, name)\n",
    "        single_image = preprocess(Image.open(single_image_path)).unsqueeze(0)\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            single_image_features = model.encode_image(single_image)\n",
    "            single_image_features /= single_image_features.norm(dim=-1, keepdim=True)\n",
    "            torch.save(single_image_features, os.path.join(feature_root, pre + '.pt'))\n",
    "    break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-06c60d1c4c2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'euclidean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\81570\\.conda\\envs\\torch3.6\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    184\u001b[0m             raise RuntimeError(\n\u001b[0;32m    185\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             raise AssertionError(\n",
      "\u001b[1;32mc:\\Users\\81570\\.conda\\envs\\torch3.6\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from fast_pytorch_kmeans import KMeans\n",
    "import torch\n",
    "\n",
    "kmeans = KMeans(n_clusters=8, mode='euclidean', verbose=1)\n",
    "x = torch.randn(100000, 64, device='cuda')\n",
    "labels = kmeans.fit_predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import re\n",
    "\n",
    "dir_path = \"/home/zhengwei/Desktop/Zhengwei/Projects/datasets/DukeMTMC-reID/tensors/train_all\"\n",
    "tensor_paths = glob.glob(osp.join(dir_path, '*/*.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/zhengwei/Desktop/Zhengwei/Projects/datasets/DukeMTMC-reID/tensors/train_all/4509/4509_c6_f0110693.pt', '/home/zhengwei/Desktop/Zhengwei/Projects/datasets/DukeMTMC-reID/tensors/train_all/4509/4509_c8_f0088384.pt', '/home/zhengwei/Desktop/Zhengwei/Projects/datasets/DukeMTMC-reID/tensors/train_all/4509/4509_c7_f0115296.pt', '/home/zhengwei/Desktop/Zhengwei/Projects/datasets/DukeMTMC-reID/tensors/train_all/4509/4509_c6_f0110813.pt', '/home/zhengwei/Desktop/Zhengwei/Projects/datasets/DukeMTMC-reID/tensors/train_all/4509/4509_c8_f0088264.pt', '/home/zhengwei/Desktop/Zhengwei/Projects/datasets/DukeMTMC-reID/tensors/train_all/4509/4509_c6_f0111053.pt', '/home/zhengwei/Desktop/Zhengwei/Projects/datasets/DukeMTMC-reID/tensors/train_all/4509/4509_c6_f0111173.pt', '/home/zhengwei/Desktop/Zhengwei/Projects/datasets/DukeMTMC-reID/tensors/train_all/4509/4509_c7_f0115056.pt', '/home/zhengwei/Desktop/Zhengwei/Projects/datasets/DukeMTMC-reID/tensors/train_all/4509/4509_c6_f0110933.pt', '/home/zhengwei/Desktop/Zhengwei/Projects/datasets/DukeMTMC-reID/tensors/train_all/4509/4509_c8_f0088504.pt']\n",
      "243\n"
     ]
    }
   ],
   "source": [
    "print(tensor_paths[:10])\n",
    "print(len(tensor_paths))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([243, 512])\n"
     ]
    }
   ],
   "source": [
    "# 将路径下所有的tensor保存成一个全部tensor，维度为（数量，维度）\n",
    "all_tensors = []\n",
    "for tensor_path in tensor_paths:\n",
    "    tensor = torch.load(tensor_path)\n",
    "    all_tensors.append(tensor)\n",
    "all_tensors = torch.cat(all_tensors, dim=0)\n",
    "all_tensors = all_tensors.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used 6 iterations (0.0288s) to cluster 243 items into 25 clusters\n",
      "torch.Size([243])\n",
      "torch.Size([25, 512])\n",
      "{'labels': tensor([ 0,  8,  8,  8,  8,  8,  0,  8,  0, 19,  0,  1, 19,  8,  9,  1,  9,  9,\n",
      "        16, 23,  2, 24, 24,  8,  1,  9, 23,  5,  9,  2,  1,  2,  5, 18,  5,  2,\n",
      "        21, 21,  5,  1, 10,  5, 12, 24, 19, 12,  5,  5,  1, 19, 19,  5, 10,  3,\n",
      "         5, 24,  3,  5, 24,  5,  5, 19, 12,  3, 12,  3,  3, 24,  5, 13, 24,  5,\n",
      "         5,  5, 17,  5,  5,  5,  5,  5, 17,  5, 23, 13, 11,  5, 13, 11,  8,  5,\n",
      "         8,  8,  8,  8,  0,  5,  0, 15, 14, 19,  0, 13, 13,  8,  8, 21, 15, 13,\n",
      "         9,  5,  6, 23, 19, 13,  8,  5,  5,  5,  5, 13,  8,  5,  8, 13, 13,  8,\n",
      "        17,  5, 16, 23,  8,  5,  8,  0,  8,  5, 18,  9,  9, 21,  8, 19, 21,  9,\n",
      "        23, 18, 21,  9,  5, 17,  5, 11,  8,  9, 21,  9, 21,  9,  7,  8, 13, 21,\n",
      "         8,  4,  8,  3,  7,  4,  5,  5,  4,  4,  7,  4,  5,  1,  7,  7,  7,  4,\n",
      "         5,  4,  4,  7,  1,  4,  7,  9,  8, 20,  1,  1, 20,  8,  8, 23,  1, 17,\n",
      "        17, 17,  1,  9, 20, 19,  1, 20,  1, 20, 20,  1,  1, 20,  1,  8,  1, 17,\n",
      "         1,  1,  9,  1,  1,  1,  1, 20,  1, 20, 20,  8,  1,  1,  9,  9,  9, 17,\n",
      "         1, 19,  1, 20,  9,  1,  1, 20, 20], device='cuda:0'), 'path2label': {'4509_c6_f0110693': 0, '4509_c8_f0088384': 8, '4509_c7_f0115296': 8, '4509_c6_f0110813': 8, '4509_c8_f0088264': 8, '4509_c6_f0111053': 8, '4509_c6_f0111173': 0, '4509_c7_f0115056': 8, '4509_c6_f0110933': 0, '4509_c8_f0088504': 19, '4509_c6_f0110573': 0, '4509_c7_f0115176': 1, '4509_c7_f0114936': 19, '0447_c1_f0121336': 8, '0447_c1_f0121456': 9, '0447_c2_f0121601': 1, '0447_c1_f0121216': 9, '0447_c1_f0121096': 9, '0447_c2_f0121001': 16, '0447_c1_f0121696': 23, '0447_c1_f0121576': 2, '0447_c2_f0121241': 24, '0447_c2_f0120881': 24, '0447_c2_f0121481': 8, '0447_c2_f0121361': 1, '0447_c2_f0121121': 9, '0447_c1_f0121816': 23, '0178_c2_f0086820': 5, '0178_c2_f0086340': 9, '0178_c3_f0061706': 2, '0178_c2_f0086700': 1, '0178_c1_f0086227': 2, '0178_c4_f0056594': 5, '0178_c4_f0055994': 18, '0178_c2_f0086580': 5, '0178_c1_f0086107': 2, '0178_c3_f0061946': 21, '0178_c3_f0062066': 21, '0178_c3_f0061826': 5, '0178_c4_f0056114': 1, '0178_c3_f0061586': 10, '0178_c4_f0056714': 5, '0178_c1_f0086347': 12, '0178_c4_f0056234': 24, '0178_c2_f0086220': 19, '0178_c1_f0086467': 12, '0178_c4_f0056354': 5, '0178_c2_f0086460': 5, '0178_c2_f0086940': 1, '0178_c4_f0055874': 19, '0178_c4_f0055754': 19, '0178_c4_f0056474': 5, '1589_c3_f0091351': 10, '1589_c4_f0088904': 3, '1589_c2_f0113550': 5, '1589_c4_f0089624': 24, '1589_c3_f0091471': 3, '1589_c4_f0089024': 5, '1589_c4_f0089384': 24, '1589_c2_f0113430': 5, '1589_c2_f0113670': 5, '1589_c4_f0089744': 19, '1589_c2_f0113790': 12, '1589_c3_f0091591': 3, '1589_c2_f0113910': 12, '1589_c3_f0091711': 3, '1589_c5_f0118264': 3, '1589_c4_f0089504': 24, '1589_c4_f0089144': 5, '1589_c5_f0118144': 13, '1589_c4_f0089264': 24, '0362_c1_f0108731': 5, '0362_c8_f0065228': 5, '0362_c1_f0108971': 5, '0362_c8_f0065468': 17, '0362_c8_f0064988': 5, '0362_c1_f0108851': 5, '0362_c8_f0064868': 5, '0362_c8_f0064748': 5, '0362_c1_f0108611': 5, '0362_c8_f0065348': 17, '0362_c8_f0065108': 5, '0362_c1_f0109331': 23, '0362_c1_f0109211': 13, '0362_c1_f0109451': 11, '0362_c1_f0108491': 5, '0362_c1_f0109091': 13, '0280_c1_f0098570': 11, '0280_c2_f0097944': 8, '0280_c2_f0098184': 5, '0280_c1_f0097970': 8, '0280_c3_f0073434': 8, '0280_c3_f0073074': 8, '0280_c2_f0098064': 8, '0280_c4_f0067773': 0, '0280_c2_f0098424': 5, '0280_c4_f0067653': 0, '0280_c4_f0068013': 15, '0280_c4_f0067893': 14, '0280_c4_f0067533': 19, '0280_c4_f0067413': 0, '0280_c1_f0098210': 13, '0280_c3_f0073194': 13, '0280_c2_f0097824': 8, '0280_c1_f0097850': 8, '0280_c3_f0073554': 21, '0280_c4_f0068133': 15, '0280_c1_f0098330': 13, '0280_c2_f0098304': 9, '0280_c3_f0073314': 5, '0280_c4_f0068253': 6, '0280_c1_f0098450': 23, '0280_c2_f0097704': 19, '0280_c1_f0098090': 13, '0411_c1_f0115738': 8, '0411_c2_f0116095': 5, '0411_c2_f0115855': 5, '0411_c2_f0115975': 5, '0411_c2_f0115735': 5, '0411_c6_f0094221': 13, '0411_c7_f0098790': 8, '0411_c5_f0118192': 5, '0411_c7_f0098550': 8, '0411_c7_f0098670': 13, '0411_c7_f0098910': 13, '0411_c2_f0116215': 8, '0411_c1_f0115978': 17, '0411_c6_f0093981': 5, '0411_c6_f0094581': 16, '0411_c1_f0116098': 23, '0411_c1_f0115858': 8, '0411_c6_f0094101': 5, '0411_c1_f0115618': 8, '0411_c6_f0094461': 0, '0411_c1_f0115498': 8, '0411_c5_f0118312': 5, '0411_c6_f0094341': 18, '0510_c1_f0132009': 9, '0510_c1_f0132489': 9, '0510_c4_f0110626': 21, '0510_c3_f0112891': 8, '0510_c2_f0135831': 19, '0510_c4_f0110266': 21, '0510_c1_f0131504': 9, '0510_c1_f0131144': 23, '0510_c2_f0136191': 18, '0510_c2_f0136071': 21, '0510_c1_f0131384': 9, '0510_c3_f0113131': 5, '0510_c4_f0110866': 17, '0510_c4_f0110386': 5, '0510_c1_f0131024': 11, '0510_c1_f0131264': 8, '0510_c1_f0132129': 9, '0510_c4_f0110506': 21, '0510_c1_f0132249': 9, '0510_c4_f0110146': 21, '0510_c1_f0132369': 9, '0510_c3_f0113011': 7, '0510_c4_f0110746': 8, '0510_c3_f0113251': 13, '0510_c1_f0131889': 21, '0510_c2_f0135951': 8, '1794_c2_f0158402': 4, '1794_c2_f0159002': 8, '1794_c4_f0133322': 3, '1794_c2_f0158882': 7, '1794_c4_f0134162': 4, '1794_c2_f0157802': 5, '1794_c2_f0158162': 5, '1794_c2_f0158522': 4, '1794_c4_f0133922': 4, '1794_c2_f0157922': 7, '1794_c4_f0133562': 4, '1794_c4_f0133442': 5, '1794_c2_f0158642': 1, '1794_c3_f0135985': 7, '1794_c3_f0135865': 7, '1794_c3_f0136225': 7, '1794_c4_f0133682': 4, '1794_c2_f0158042': 5, '1794_c2_f0158282': 4, '1794_c4_f0134042': 4, '1794_c3_f0135745': 7, '1794_c2_f0158762': 1, '1794_c4_f0133802': 4, '1794_c3_f0136105': 7, '0166_c5_f0079192': 9, '0166_c2_f0083178': 8, '0166_c5_f0083272': 20, '0166_c5_f0080272': 1, '0166_c5_f0079432': 1, '0166_c5_f0082312': 20, '0166_c2_f0083658': 8, '0166_c2_f0083418': 8, '0166_c1_f0084868': 23, '0166_c5_f0080392': 1, '0166_c2_f0084138': 17, '0166_c1_f0084508': 17, '0166_c1_f0084388': 17, '0166_c5_f0079312': 1, '0166_c5_f0081592': 9, '0166_c2_f0084018': 20, '0166_c1_f0084988': 19, '0166_c1_f0084628': 1, '0166_c5_f0082552': 20, '0166_c5_f0079912': 1, '0166_c5_f0083392': 20, '0166_c5_f0082072': 20, '0166_c1_f0084268': 1, '0166_c2_f0083898': 1, '0166_c5_f0083152': 20, '0166_c5_f0081352': 1, '0166_c1_f0084028': 8, '0166_c5_f0081232': 1, '0166_c2_f0083538': 17, '0166_c5_f0080032': 1, '0166_c5_f0080632': 1, '0166_c5_f0079072': 9, '0166_c5_f0080992': 1, '0166_c5_f0081112': 1, '0166_c5_f0079672': 1, '0166_c2_f0083778': 1, '0166_c5_f0083032': 20, '0166_c5_f0080152': 1, '0166_c5_f0082672': 20, '0166_c5_f0082192': 20, '0166_c1_f0084748': 8, '0166_c1_f0084148': 1, '0166_c5_f0080872': 1, '0166_c5_f0081712': 9, '0166_c5_f0081832': 9, '0166_c5_f0079552': 9, '0166_c5_f0083512': 17, '0166_c5_f0080512': 1, '0166_c2_f0083298': 19, '0166_c5_f0080752': 1, '0166_c5_f0082432': 20, '0166_c5_f0081952': 9, '0166_c5_f0079792': 1, '0166_c5_f0081472': 1, '0166_c5_f0082912': 20, '0166_c5_f0082792': 20}, 'centroids': tensor([[-0.0088, -0.1051,  0.0268,  ..., -0.0333, -0.0073,  0.0047],\n",
      "        [-0.0221, -0.1729,  0.0682,  ...,  0.0004, -0.0042,  0.0073],\n",
      "        [-0.0525, -0.1059,  0.0627,  ..., -0.0041,  0.0015,  0.0063],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0081, -0.0876,  0.0933,  ...,  0.0185,  0.0253,  0.0066],\n",
      "        [-0.0127, -0.1117,  0.0627,  ..., -0.0369, -0.0113, -0.0204]],\n",
      "       device='cuda:0', dtype=torch.float16)}\n"
     ]
    }
   ],
   "source": [
    "from fast_pytorch_kmeans import KMeans\n",
    "# 使用kmeans聚类\n",
    "k = 25\n",
    "sim_mode = 'euclidean'\n",
    "kmeans = KMeans(n_clusters=k, mode=sim_mode, verbose=1)\n",
    "labels = kmeans.fit_predict(all_tensors)\n",
    "centroids = kmeans.centroids\n",
    "\n",
    "path2label = {}\n",
    "for i, tensor_path in enumerate(tensor_paths):\n",
    "    file_name = osp.basename(tensor_path)\n",
    "    file_name = re.sub(r'\\.pt$', '', file_name)\n",
    "    label = labels[i].item()\n",
    "    path2label[file_name] = label\n",
    "\n",
    "print(labels.shape)\n",
    "print(centroids.shape)\n",
    "# 保存labels和centroids\n",
    "result={}\n",
    "result['labels'] = labels\n",
    "result['path2label'] = path2label \n",
    "result['centroids'] = centroids # shape=(num_clusters, feature_dim)\n",
    "print(result)\n",
    "\n",
    "\n",
    "# save_path = \"/Kmeans_result/DukeMTMC-reID/{}k_{}.pt\".format(k, sim_mode)\n",
    "# torch.save(result, save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:/Datasets/DukeMTMC-reID/pytorch/train_all\\\\0001\\\\0001_c2_f0046182.jpg', 'D:/Datasets/DukeMTMC-reID/pytorch/train_all\\\\0001\\\\0001_c2_f0046302.jpg', 'D:/Datasets/DukeMTMC-reID/pytorch/train_all\\\\0001\\\\0001_c2_f0046422.jpg', 'D:/Datasets/DukeMTMC-reID/pytorch/train_all\\\\0001\\\\0001_c2_f0046542.jpg', 'D:/Datasets/DukeMTMC-reID/pytorch/train_all\\\\0001\\\\0001_c2_f0046662.jpg', 'D:/Datasets/DukeMTMC-reID/pytorch/train_all\\\\0001\\\\0001_c2_f0046782.jpg', 'D:/Datasets/DukeMTMC-reID/pytorch/train_all\\\\0001\\\\0001_c2_f0046902.jpg', 'D:/Datasets/DukeMTMC-reID/pytorch/train_all\\\\0001\\\\0001_c2_f0047022.jpg', 'D:/Datasets/DukeMTMC-reID/pytorch/train_all\\\\0001\\\\0001_c5_f0051247.jpg', 'D:/Datasets/DukeMTMC-reID/pytorch/train_all\\\\0001\\\\0001_c5_f0051367.jpg']\n",
      "1 2\n"
     ]
    }
   ],
   "source": [
    "print(img_paths[:10])\n",
    "pattern = re.compile(r'([-\\d]+)_c(\\d)')\n",
    "pid, cam = map(int, pattern.search(img_paths[0]).groups())\n",
    "print(pid, cam)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
